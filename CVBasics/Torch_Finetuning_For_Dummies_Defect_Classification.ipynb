{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch Finetuning example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedMostafaSal/UnstructuredProjects/blob/main/CVBasics/Torch_Finetuning_For_Dummies_Defect_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "  https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n"
      ],
      "metadata": {
        "id": "ScbDO6EWeVax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4alDjmOeAzI",
        "outputId": "5a6453cd-e8b3-462d-ffb8-f15f05f59046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rYI9ARFM1e55gxJEllb_avR_N9IKJsuM\n",
            "To: /content/casting_data.zip\n",
            "100% 73.0M/73.0M [00:00<00:00, 370MB/s]\n",
            "replace /content/casting_data/casting_data/casting_data/test/def_front/cast_def_0_1059.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1rYI9ARFM1e55gxJEllb_avR_N9IKJsuM\n",
        "!unzip -qq \"/content/casting_data.zip\" -d \"/content/casting_data/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MrtCF0XeCW4",
        "outputId": "5663bc76-91ba-423d-8060-f0b91570a41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.12.0+cu113\n",
            "Torchvision Version:  0.13.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[resnet, alexnet, vgg, squeezenet, densenet, inception]"
      ],
      "metadata": {
        "id": "8XjWUr9jedts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = \"/content/casting_data/casting_data/casting_data\"\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"squeezenet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "metadata": {
        "id": "EdwvbeIvexVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Loader \n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=\"/content/casting_data/casting_data/casting_data/train\")\n",
        "test_dataset = datasets.ImageFolder(root=\"/content/casting_data/casting_data/casting_data/test\")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        " )\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        " )"
      ],
      "metadata": {
        "id": "UQYtabYKfFBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmB_waPViJ2K",
        "outputId": "36e7755d-d5e4-433a-dc54-495e9226f8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "830"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N9ffrmBkze6",
        "outputId": "df4eedc9-07b1-494a-c39a-117bf357fa0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'test':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "7MYEMTD1gwPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "0uasXtwng-f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG52gEnghBqP",
        "outputId": "88164db8-ee72-4496-f638-2b6c0173b195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "# Centre crop is a mistake for this dataset\n",
        "#Add normalisation to your images (Get them from the imageNet documentation when needed)\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "#        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.Resize(input_size),\n",
        "#        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "#        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSqPb7-nhdPm",
        "outputId": "dc846cd5-d4fe-4811-d16f-655bf0909cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jJkl8erhiyl",
        "outputId": "d30ec71c-fa68-4da0-b9a7-77768777dccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t classifier.1.weight\n",
            "\t classifier.1.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CCf8XwDnVVf",
        "outputId": "c7e8657b-9450-4926-c3a7-e6476880575b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.2815 Acc: 0.8726\n",
            "test Loss: 0.0988 Acc: 0.9706\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.1376 Acc: 0.9496\n",
            "test Loss: 0.0715 Acc: 0.9874\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.1060 Acc: 0.9613\n",
            "test Loss: 0.0550 Acc: 0.9860\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.0946 Acc: 0.9649\n",
            "test Loss: 0.0950 Acc: 0.9650\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.0880 Acc: 0.9665\n",
            "test Loss: 0.0449 Acc: 0.9874\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.0865 Acc: 0.9679\n",
            "test Loss: 0.0486 Acc: 0.9846\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.0723 Acc: 0.9750\n",
            "test Loss: 0.0525 Acc: 0.9804\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.0729 Acc: 0.9717\n",
            "test Loss: 0.0328 Acc: 0.9888\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.0707 Acc: 0.9742\n",
            "test Loss: 0.0345 Acc: 0.9874\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.0675 Acc: 0.9748\n",
            "test Loss: 0.0527 Acc: 0.9818\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0667 Acc: 0.9765\n",
            "test Loss: 0.0304 Acc: 0.9930\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0677 Acc: 0.9763\n",
            "test Loss: 0.0799 Acc: 0.9664\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0637 Acc: 0.9766\n",
            "test Loss: 0.0289 Acc: 0.9902\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0616 Acc: 0.9777\n",
            "test Loss: 0.0313 Acc: 0.9930\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0629 Acc: 0.9790\n",
            "test Loss: 0.0312 Acc: 0.9888\n",
            "\n",
            "Training complete in 6m 22s\n",
            "Best val Acc: 0.993007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the non-pretrained version of the model used for this run\n",
        "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "scratch_model = scratch_model.to(device)\n",
        "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
        "scratch_criterion = nn.CrossEntropyLoss()\n",
        "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
        "\n",
        "# Plot the training curves of validation accuracy vs. number\n",
        "#  of training epochs for the transfer learning method and\n",
        "#  the model trained from scratch\n",
        "ohist = []\n",
        "shist = []\n",
        "\n",
        "ohist = [h.cpu().numpy() for h in hist]\n",
        "shist = [h.cpu().numpy() for h in scratch_hist]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
        "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HJlUv4NQnZLk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8725f6f7-f059-4a1b-f7cb-7c95137bfa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.6741 Acc: 0.5703\n",
            "test Loss: 0.6500 Acc: 0.6336\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.6795 Acc: 0.5720\n",
            "test Loss: 0.6582 Acc: 0.6336\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.6388 Acc: 0.5830\n",
            "test Loss: 0.6596 Acc: 0.6336\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6536 Acc: 0.6175\n",
            "test Loss: 0.4176 Acc: 0.8615\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.5529 Acc: 0.6958\n",
            "test Loss: 0.4009 Acc: 0.8266\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.4677 Acc: 0.7826\n",
            "test Loss: 0.3995 Acc: 0.7664\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.4323 Acc: 0.8022\n",
            "test Loss: 0.3121 Acc: 0.8755\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.4185 Acc: 0.8079\n",
            "test Loss: 0.2739 Acc: 0.8979\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.2335 Acc: 0.9062\n",
            "test Loss: 0.3476 Acc: 0.8196\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.1509 Acc: 0.9457\n",
            "test Loss: 0.0863 Acc: 0.9748\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.0903 Acc: 0.9727\n",
            "test Loss: 0.0571 Acc: 0.9846\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.0713 Acc: 0.9762\n",
            "test Loss: 0.0827 Acc: 0.9692\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.0796 Acc: 0.9754\n",
            "test Loss: 0.0550 Acc: 0.9860\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.0405 Acc: 0.9893\n",
            "test Loss: 0.0484 Acc: 0.9846\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.0392 Acc: 0.9897\n",
            "test Loss: 0.0428 Acc: 0.9860\n",
            "\n",
            "Training complete in 8m 7s\n",
            "Best val Acc: 0.986014\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dm6tc5dXndTG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}